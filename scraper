"""
YouTube Niche Scraper

Objectif : Trouver et filtrer automatiquement des cha√Ænes YouTube faceless qui remplissent les crit√®res suivants :
- Moins de 6 mois depuis la premi√®re vid√©o publi√©e
- Entre 10,000 et 20,000 abonn√©s
- Moins de 20 vid√©os au total
- Au moins une vid√©o ayant plus de 500,000 vues

Pour chaque cha√Æne, collecter :
- Nom de la cha√Æne
- URL de la cha√Æne
- Nombre d‚Äôabonn√©s
- Nombre total de vid√©os
- Date de la premi√®re vid√©o publi√©e
- Nombre total de vues
- Nombre de vues de la vid√©o la plus populaire

R√©sultats export√©s dans un fichier CSV propre : "youtube_channels_filtered.csv"

Langage : Python
Librairies : googleapiclient (YouTube Data API v3), pandas, datetime, csv
"""

import os
import pandas as pd
from googleapiclient.discovery import build
from datetime import datetime
import time

# ---- CONFIGURATION ---- #
API_KEY = os.environ.get("YOUTUBE_API_KEY")
if not API_KEY:
    raise RuntimeError(
        "The YOUTUBE_API_KEY environment variable must be set with a valid "
        "YouTube Data API v3 key."
    )
SEARCH_KEYWORDS = ["self improvement", "AI tools", "wealth mindset", "luxury lifestyle", "crypto news"]
MAX_RESULTS = 10  # per keyword
OUTPUT_FILE = "youtube_channels_filtered.csv"

# ---- INITIATE API CLIENT ---- #
youtube = build('youtube', 'v3', developerKey=API_KEY)

# ---- FUNCTION TO GET CHANNEL STATS ---- #
def get_channel_details(channel_id):
    request = youtube.channels().list(
        part="snippet,statistics,contentDetails",
        id=channel_id
    )
    response = request.execute()
    
    if not response['items']:
        return None

    item = response['items'][0]
    
    stats = item['statistics']
    snippet = item['snippet']
    uploads_playlist = item['contentDetails']['relatedPlaylists']['uploads']
    
    return {
        "channel_title": snippet['title'],
        "channel_url": f"https://www.youtube.com/channel/{channel_id}",
        "subscribers": int(stats.get('subscriberCount', 0)),
        "total_views": int(stats.get('viewCount', 0)),
        "total_videos": int(stats.get('videoCount', 0)),
        "uploads_playlist_id": uploads_playlist,
        "channel_id": channel_id
    }

# ---- FUNCTION TO GET VIDEOS FROM PLAYLIST ---- #
def get_playlist_videos(playlist_id, max_results=50):
    video_data = []
    next_page_token = None

    while True:
        request = youtube.playlistItems().list(
            part="snippet,contentDetails",
            playlistId=playlist_id,
            maxResults=50,
            pageToken=next_page_token
        )
        response = request.execute()

        video_data.extend(response['items'])

        next_page_token = response.get('nextPageToken')
        if not next_page_token or len(video_data) >= max_results:
            break

    return video_data

# ---- FUNCTION TO GET VIEW COUNTS FOR VIDEOS ---- #
def get_video_stats(video_ids):
    request = youtube.videos().list(
        part="statistics,snippet",
        id=",".join(video_ids[:50])
    )
    response = request.execute()

    video_info = []
    for video in response['items']:
        stats = video['statistics']
        snippet = video['snippet']
        published = snippet['publishedAt']
        views = int(stats.get('viewCount', 0))
        video_info.append({
            "video_id": video['id'],
            "views": views,
            "publishedAt": published
        })

    return video_info

# ---- MAIN SCRAPER FUNCTION ---- #
filtered_channels = []

for keyword in SEARCH_KEYWORDS:
    print(f"\nüîç Searching for keyword: {keyword}")
    
    search_response = youtube.search().list(
        q=keyword,
        type="channel",
        part="snippet",
        maxResults=MAX_RESULTS
    ).execute()

    for item in search_response['items']:
        channel_id = item['snippet']['channelId']
        channel_data = get_channel_details(channel_id)
        if not channel_data:
            continue

        # Filter 1: Subscriber count
        if channel_data['subscribers'] < 10000 or channel_data['subscribers'] > 20000:
            continue

        # Filter 2: Number of videos
        if channel_data['total_videos'] > 20:
            continue

        # Get videos to determine first upload date and max views
        playlist_videos = get_playlist_videos(channel_data['uploads_playlist_id'])
        if len(playlist_videos) == 0:
            continue

        video_ids = [v['contentDetails']['videoId'] for v in playlist_videos]
        video_stats = get_video_stats(video_ids)
        
        # Sort videos by publish date
        video_stats_sorted = sorted(video_stats, key=lambda x: x['publishedAt'])
        first_video_date = datetime.strptime(video_stats_sorted[0]['publishedAt'], "%Y-%m-%dT%H:%M:%SZ")
        age_in_months = (datetime.utcnow() - first_video_date).days / 30

        # Filter 3: Channel must be less than 6 months old
        if age_in_months > 6:
            continue

        # Find highest viewed video
        max_views = max(v['views'] for v in video_stats)

        # Filter 4: At least one video with > 500k views
        if max_views < 500000:
            continue

        # ‚úÖ Passed all filters
        channel_data['first_video_date'] = first_video_date.strftime("%Y-%m-%d")
        channel_data['max_video_views'] = max_views
        filtered_channels.append(channel_data)
        print(f"‚úÖ Channel added: {channel_data['channel_title']}")

        time.sleep(1)  # Respect API limits

# ---- EXPORT TO CSV ---- #
df = pd.DataFrame(filtered_channels)
df.to_csv(OUTPUT_FILE, index=False)
print(f"\nüìÅ Exported {len(filtered_channels)} channels to {OUTPUT_FILE}")
